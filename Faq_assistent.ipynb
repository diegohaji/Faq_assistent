{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Insira seu token de acesso pessoal\n",
    "login(\"Your_HuggingFace_API_Key\",add_to_git_credential=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device = 'cuda',\n",
    "    \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Função para carregar e formatar o FAQ a partir de um CSV\n",
    "def carregar_faq_do_csv(caminho_csv):\n",
    "    try:\n",
    "        # Lendo o CSV com pandas\n",
    "        df = pd.read_csv(caminho_csv)\n",
    "        # Verifica se as colunas \"Pergunta\" e \"Resposta\" existem\n",
    "        if \"Pergunta\" not in df.columns or \"Resposta\" not in df.columns:\n",
    "            raise ValueError(\"O arquivo CSV deve conter colunas 'Pergunta' e 'Resposta'.\")\n",
    "        \n",
    "        # Concatena as perguntas e respostas no formato desejado\n",
    "        faq_text = \"\\n\".join(f\"- {row['Pergunta']} {row['Resposta']}\" for _, row in df.iterrows())\n",
    "        return faq_text\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao carregar o FAQ: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Carregar o CSV\n",
    "caminho_csv = \"FAQ.csv\"  # Substitua pelo caminho do seu arquivo CSV\n",
    "FAQ = carregar_faq_do_csv(caminho_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "\n",
    "# Função para gerar a resposta\n",
    "def gerar_resposta(pergunta, faq, fallback=\"Não sei responder a essa pergunta. Por favor, tente perguntar de outra forma ou consulte nosso FAQ.\"):\n",
    "    prompt = f\"\"\"\n",
    "    Você é um assistente que responde perguntas com base exclusivamente no seguinte FAQ. \n",
    "    Não inclua o texto do FAQ na resposta, apenas use-o como referência para responder à pergunta.\n",
    "\n",
    "    FAQ:\n",
    "    \\\"\\\"\\\"{faq}\\\"\\\"\\\"\n",
    "\n",
    "    Responda à seguinte pergunta de forma direta e objetiva:\n",
    "\n",
    "    Pergunta: {pergunta}\n",
    "    Resposta:\n",
    "    \"\"\"\n",
    "    # Gera a resposta com o modelo\n",
    "    outputs = pipe(\n",
    "        prompt,\n",
    "        max_new_tokens=100,  # Limite o número de tokens gerados para respostas curtas\n",
    "        pad_token_id=50256  # Configuração explícita para evitar warnings\n",
    "    )\n",
    "    # Extrai somente a parte gerada como resposta\n",
    "    resposta_gerada = outputs[0][\"generated_text\"].strip()\n",
    "    \n",
    "    # Remove o prompt inicial da resposta, caso seja incluído pelo modelo\n",
    "    resposta = resposta_gerada.split(\"Resposta:\", 1)[-1].strip()\n",
    "\n",
    "    # Remove repetições redundantes\n",
    "    palavras = resposta.split()\n",
    "    resposta_filtrada = \" \".join(dict.fromkeys(palavras))  # Remove palavras repetidas consecutivas\n",
    "    \n",
    "    # Verifica se a resposta é válida, caso contrário, usa o fallback\n",
    "    if not resposta_filtrada or \"não tenho informações\" in resposta_filtrada.lower():\n",
    "        return fallback\n",
    "    \n",
    "    return resposta_filtrada\n",
    "\n",
    "# Função para processar a pergunta do usuário\n",
    "def processar_pergunta():\n",
    "    pergunta = entrada_pergunta.get()  # Obtem a pergunta do campo de entrada\n",
    "    resposta = gerar_resposta(pergunta, FAQ)  # Gera a resposta\n",
    "    label_resposta.config(text=f\"Resposta: {resposta}\")  # Exibe a resposta\n",
    "\n",
    "\n",
    "# Configuração da janela principal\n",
    "root = tk.Tk()\n",
    "root.title(\"Assistente FAQ\")\n",
    "root.geometry(\"600x400\")\n",
    "root.configure(bg=\"#0f0fff\")  # Cor de fundo azul claro\n",
    "\n",
    "\n",
    "# Campo de entrada de pergunta\n",
    "label_pergunta = tk.Label(root, text=\"Digite sua pergunta:\")\n",
    "label_pergunta.pack(pady=(20, 5))  # Espaçamento superior maior\n",
    "label_pergunta.config(bg=\"#f0f8ff\", font=(\"Arial\", 14))\n",
    "\n",
    "entrada_pergunta = tk.Entry(root, width=50)\n",
    "entrada_pergunta.pack(pady=10, padx=20)  # Espaçamento interno horizontal\n",
    "entrada_pergunta.config(font=(\"Arial\", 12))\n",
    "\n",
    "# Botão para enviar a pergunta\n",
    "botao_enviar = ttk.Button(root, text=\"Obter Resposta\", command=processar_pergunta)\n",
    "botao_enviar.pack(pady=10)\n",
    "botao_enviar.config(style=\"TButton\")\n",
    "\n",
    "# Área para exibir a resposta\n",
    "label_resposta = tk.Label(root, text=\"Resposta: \")\n",
    "label_resposta.pack(pady=20, padx=20)  # Adicionar espaçamento lateral para respostas longas\n",
    "label_resposta.config(bg=\"#f0f8ff\", font=(\"Arial\", 12), wraplength=500, fg=\"#333\")\n",
    "\n",
    "\n",
    "# Executa o loop principal da interface\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
